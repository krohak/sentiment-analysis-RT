{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Neural Netoworks on the RT dataset\n",
    "created by krohak on 2018-03-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "from random import randint\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation is divided into three parts. \n",
    "- In the first part, we outline how to create an IDs Matrix, which is a matrix containing the vector ID of each word in all files in the dataset. This code is provided in the `preprocess.py` file.\n",
    "- In the second part, we create our neural network and train it on the preprocessed data. This code is in the `train.py` file\n",
    "- In the third part, we test our neural network. `test.py` has the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preprocessing the data, we need to create word vectors from each word, in each file of the positive and negative folders. We're going to be using [GloVe](http://nlp.stanford.edu/projects/glove/), a pretrained model which contains 400,000 word vectors. We will be using the [Wikipedia dataset with 50 dimensional embedding](https://www.damienpontifex.com/2017/10/27/using-pre-trained-glove-embeddings-in-tensorflow/).\n",
    "\n",
    "After performing `tar -xvzf data.tar.gz`, we get wordsList.npy, wordVectors.npy and idsMatrix2.py. wordsList is the list with the 400,000 words and wordVectors is a 400,000 x 50 dimensional embedding matrix that holds all of the word vector values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = np.load('wordsList.npy')\n",
    "wordsList = wordsList.tolist() \n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] \n",
    "wordVectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the ids matrix for the whole dataset, letâ€™s first take some time to visualize the type of data that we have. This will help us determine the best value for setting our maximum sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_sentoken/pos/cv091_7400.txt\n",
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 2000\n",
      "The total number of words in the files is 1492681\n",
      "The average number of words in the files is 746.3405\n"
     ]
    }
   ],
   "source": [
    "positiveFiles = ['txt_sentoken/pos/' + f for f in listdir('txt_sentoken/pos/') if isfile(join('txt_sentoken/pos/', f))]\n",
    "negativeFiles = ['txt_sentoken/neg/' + f for f in listdir('txt_sentoken/neg/') if isfile(join('txt_sentoken/neg/', f))]\n",
    "print(positiveFiles[0])\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        lines=f.readlines()\n",
    "        counter = 0\n",
    "        for line in lines:\n",
    "            counter += len(line.split())\n",
    "        numWords.append(counter)\n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        lines=f.readlines()\n",
    "        counter = 0\n",
    "        for line in lines:\n",
    "            counter += len(line.split())\n",
    "        numWords.append(counter)\n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2678"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(numWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data in a histogram, so that we can compare the frequences and sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/7G6JWCwoRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff38f788be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram as well as the average number of words per file, we can safely say that most reviews will fall under 750 words, which is the max sequence length value we will set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a single file and transform it into our ids matrix. This is what the first line of one of the reviews looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_sentoken/pos/cv897_10837.txt\n",
      "i must admit that i was a tad skeptical of \" good will hunting \" , based both on the previews and the first fifteen minutes of the film , in which the main character will hunting ( matt damon ) , an mit janitor in his early twenties , is discovered to be an einstein-level closet genius when he solves two extraordinarily difficult math problems overnight . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = positiveFiles[740] #Can use any valid index (not just 3)\n",
    "print(fname)\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function for removing punctuation, parentheses, question marks, etc., and leave only alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert to to an ids matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (750,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([     6,     42,     78,   2103,     88,      6,    853,   1650,\n",
       "            43,  11228,    101,    138,     17,      7,  57044,  19980,\n",
       "         11225,      3,    473,    417,   4311,      6,    637,  16574,\n",
       "          1483,     17,     26,   1095,     96,   3722,  49733,   2663,\n",
       "         25859,     14,   1140,    871,  18068,     83,   3779,   2241,\n",
       "        201534,    319,     31,    558,   2054,      3, 201534,   3880,\n",
       "          1388,     42,     15,     96,    647, 201534,   1247,     10,\n",
       "            47, 399999,      5,  20001,   1003,    143,      4, 201534,\n",
       "           380,      3,  16574,   1395,   1679,     64,     37,      4,\n",
       "        201534,    853,     12,    219,     43,   4429,    151,   6297,\n",
       "             4,   2933,    138,     29,  28687,   1751,   1945,    296,\n",
       "           881,  23808,  17614,      5,     81,    414,     30,   9215,\n",
       "           738,     41, 201398,    454,     37,    319,    133,   1569,\n",
       "           143,     10,     48,    873,     84,   1120,    197,    143,\n",
       "         10820,      5,  25859,     38,    836, 201534,   9045,      5,\n",
       "           369,  17788,   1461,  17354,   2933,     20,    138, 201534,\n",
       "           523,     14,    149,    871,  30761,      5,     36,   1113,\n",
       "           929,     63,     32,     52,      7,    306,   3468,     12,\n",
       "           119,    998,      7,   1594,  44004,    144], dtype=int32), None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        #print(split)\n",
    "        for word in split:\n",
    "            if indexCounter < maxSeqLength:\n",
    "                try:\n",
    "                    firstFile[indexCounter] = wordsList.index(word)\n",
    "                except ValueError:\n",
    "                    firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "            indexCounter = indexCounter + 1\n",
    "firstFile[600:], print(\"shape:\", firstFile.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for each of our 2000 reviews in the Rotten Tomatoes dataset. \n",
    "\n",
    "Instead of computing the ids matrix, we can load in a pre-computed IDs matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "\n",
    "# fileCounter = 0\n",
    "\n",
    "# for pf in positiveFiles:\n",
    "#     with open(pf, \"r\") as f:\n",
    "#         indexCounter = 0\n",
    "#         lines=f.readlines()\n",
    "#         for line in lines:\n",
    "#             cleanedLine = cleanSentences(line)\n",
    "#             split = cleanedLine.split()\n",
    "#             for word in split:\n",
    "#                 try:\n",
    "#                     ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#                 except ValueError:\n",
    "#                     ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#                 print(fileCounter,indexCounter)\n",
    "#                 indexCounter = indexCounter + 1\n",
    "#                 if indexCounter >= maxSeqLength:\n",
    "#                     break\n",
    "#             if indexCounter >= maxSeqLength:\n",
    "#                     break\n",
    "#         fileCounter = fileCounter + 1\n",
    "\n",
    "# for nf in negativeFiles:\n",
    "#     with open(nf, \"r\") as f:\n",
    "#         indexCounter = 0\n",
    "#         lines=f.readlines()\n",
    "#         for line in lines:\n",
    "#             cleanedLine = cleanSentences(line)\n",
    "#             split = cleanedLine.split()\n",
    "#             for word in split:\n",
    "#                 try:\n",
    "#                     ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#                 except ValueError:\n",
    "#                     ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#                 indexCounter = indexCounter + 1\n",
    "#                 if indexCounter >= maxSeqLength:\n",
    "#                     break\n",
    "#             if indexCounter >= maxSeqLength:\n",
    "#                     break\n",
    "#         fileCounter = fileCounter + 1\n",
    "\n",
    "# np.save('idsMatrix2', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load precomputed ids\n",
    "ids = np.load('idsMatrix2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 750)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, weâ€™re ready to start creating our Tensorflow graph. Weâ€™ll first need to define some hyperparameters, such as batch size, number of LSTM units, number of output classes, and number of training iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000\n",
    "numDimensions = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our input data placeholder, weâ€™re going to call the tf.nn.embedding_lookup() function in order to get our word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™re then going to call the tf.nn.rnn_cell.BasicLSTMCell function.  Weâ€™ll then wrap that LSTM cell in a dropout layer to help prevent the network from overfitting. Finally, weâ€™ll feed both the LSTM cell and the 3-D tensor full of input data into a function called tf.nn.dynamic_rnn. This function is in charge of unrolling the whole network and creating a pathway for the data to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first output of the dynamic RNN function can be thought of as the last hidden state vector. This vector will be reshaped and then multiplied by a final weight matrix and a bias term to obtain the final output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, weâ€™ll define correct prediction and accuracy metrics to track how the network is doing. The correct prediction formulation works by looking at the index of the maximum value of the 2 output values, and then seeing whether it matches with the training labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll define a standard cross entropy loss with a softmax layer put on top of the final prediction values. For the optimizer, weâ€™ll use Adam and the default learning rate of .001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard to visualize the loss and accuracy values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to get the training and testing batches. Training is done on 4/5 of the dataset and testing on 1/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0):\n",
    "            num = randint(1,979)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(1019,1999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(979,1019)\n",
    "        if (num <= 999):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model by loading in a batch of reviews and their associated labels. We compute the optimizer since that is the component that minimizes our loss function.\n",
    "\n",
    "Instead of training the network we can also load in a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Pretrained Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-60000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver = tf.train.import_meta_graph('models/pretrained_lstm.ckpt-60000.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the graph definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Placeholder', 'Placeholder_1', 'zeros', 'Variable', 'Variable/Assign', 'Variable/read', 'embedding_lookup/params_0', 'embedding_lookup', 'DropoutWrapperInit/Const', 'DropoutWrapperInit/Const_1', 'DropoutWrapperInit/Const_2', 'Rank', 'range/start', 'range/delta', 'range', 'concat/values_0', 'concat/axis', 'concat', 'transpose', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_3', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_4', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_5', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_6', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_7', 'rnn/Shape', 'rnn/strided_slice/stack', 'rnn/strided_slice/stack_1', 'rnn/strided_slice/stack_2', 'rnn/strided_slice', 'rnn/Const', 'rnn/Const_1', 'rnn/concat/axis', 'rnn/concat', 'rnn/zeros/Const', 'rnn/zeros', 'rnn/time', 'rnn/TensorArray', 'rnn/TensorArray_1', 'rnn/TensorArrayUnstack/Shape', 'rnn/TensorArrayUnstack/strided_slice/stack', 'rnn/TensorArrayUnstack/strided_slice/stack_1', 'rnn/TensorArrayUnstack/strided_slice/stack_2', 'rnn/TensorArrayUnstack/strided_slice', 'rnn/TensorArrayUnstack/range/start', 'rnn/TensorArrayUnstack/range/delta', 'rnn/TensorArrayUnstack/range', 'rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3', 'rnn/while/Enter', 'rnn/while/Enter_1', 'rnn/while/Enter_2', 'rnn/while/Enter_3', 'rnn/while/Merge', 'rnn/while/Merge_1', 'rnn/while/Merge_2', 'rnn/while/Merge_3', 'rnn/while/Less/Enter', 'rnn/while/Less', 'rnn/while/LoopCond', 'rnn/while/Switch', 'rnn/while/Switch_1', 'rnn/while/Switch_2', 'rnn/while/Switch_3', 'rnn/while/Identity', 'rnn/while/Identity_1', 'rnn/while/Identity_2', 'rnn/while/Identity_3', 'rnn/while/TensorArrayReadV3/Enter', 'rnn/while/TensorArrayReadV3/Enter_1', 'rnn/while/TensorArrayReadV3', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/shape', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/min', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/max', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/sub', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/mul', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform', 'rnn/basic_lstm_cell/kernel', 'rnn/basic_lstm_cell/kernel/Assign', 'rnn/basic_lstm_cell/kernel/read', 'rnn/basic_lstm_cell/bias/Initializer/Const', 'rnn/basic_lstm_cell/bias', 'rnn/basic_lstm_cell/bias/Assign', 'rnn/basic_lstm_cell/bias/read', 'rnn/while/rnn/basic_lstm_cell/concat/axis', 'rnn/while/rnn/basic_lstm_cell/concat', 'rnn/while/rnn/basic_lstm_cell/MatMul/Enter', 'rnn/while/rnn/basic_lstm_cell/MatMul', 'rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter', 'rnn/while/rnn/basic_lstm_cell/BiasAdd', 'rnn/while/rnn/basic_lstm_cell/Const', 'rnn/while/rnn/basic_lstm_cell/split/split_dim', 'rnn/while/rnn/basic_lstm_cell/split', 'rnn/while/rnn/basic_lstm_cell/add/y', 'rnn/while/rnn/basic_lstm_cell/add', 'rnn/while/rnn/basic_lstm_cell/Sigmoid', 'rnn/while/rnn/basic_lstm_cell/mul', 'rnn/while/rnn/basic_lstm_cell/Sigmoid_1', 'rnn/while/rnn/basic_lstm_cell/Tanh', 'rnn/while/rnn/basic_lstm_cell/mul_1', 'rnn/while/rnn/basic_lstm_cell/add_1', 'rnn/while/rnn/basic_lstm_cell/Tanh_1', 'rnn/while/rnn/basic_lstm_cell/Sigmoid_2', 'rnn/while/rnn/basic_lstm_cell/mul_2', 'rnn/while/dropout/keep_prob', 'rnn/while/dropout/Shape', 'rnn/while/dropout/random_uniform/min', 'rnn/while/dropout/random_uniform/max', 'rnn/while/dropout/random_uniform/RandomUniform', 'rnn/while/dropout/random_uniform/sub', 'rnn/while/dropout/random_uniform/mul', 'rnn/while/dropout/random_uniform', 'rnn/while/dropout/add', 'rnn/while/dropout/Floor', 'rnn/while/dropout/div', 'rnn/while/dropout/mul', 'rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter', 'rnn/while/TensorArrayWrite/TensorArrayWriteV3', 'rnn/while/add/y', 'rnn/while/add', 'rnn/while/NextIteration', 'rnn/while/NextIteration_1', 'rnn/while/NextIteration_2', 'rnn/while/NextIteration_3', 'rnn/while/Exit', 'rnn/while/Exit_1', 'rnn/while/Exit_2', 'rnn/while/Exit_3', 'rnn/TensorArrayStack/TensorArraySizeV3', 'rnn/TensorArrayStack/range/start', 'rnn/TensorArrayStack/range/delta', 'rnn/TensorArrayStack/range', 'rnn/TensorArrayStack/TensorArrayGatherV3', 'rnn/Const_2', 'rnn/Const_3', 'rnn/Rank', 'rnn/range/start', 'rnn/range/delta', 'rnn/range', 'rnn/concat_1/values_0', 'rnn/concat_1/axis', 'rnn/concat_1', 'rnn/transpose', 'truncated_normal/shape', 'truncated_normal/mean', 'truncated_normal/stddev', 'truncated_normal/TruncatedNormal', 'truncated_normal/mul', 'truncated_normal', 'Variable_1', 'Variable_1/Assign', 'Variable_1/read', 'Const', 'Variable_2', 'Variable_2/Assign', 'Variable_2/read', 'transpose_1/perm', 'transpose_1', 'Gather/indices', 'Gather', 'MatMul', 'add', 'ArgMax/dimension', 'ArgMax', 'ArgMax_1/dimension', 'ArgMax_1', 'Equal', 'Cast', 'Const_1', 'Mean', 'Rank_1', 'Shape', 'Rank_2', 'Shape_1', 'Sub/y', 'Sub', 'Slice/begin', 'Slice/size', 'Slice', 'concat_1/values_0', 'concat_1/axis', 'concat_1', 'Reshape', 'Rank_3', 'Shape_2', 'Sub_1/y', 'Sub_1', 'Slice_1/begin', 'Slice_1/size', 'Slice_1', 'concat_2/values_0', 'concat_2/axis', 'concat_2', 'Reshape_1', 'SoftmaxCrossEntropyWithLogits', 'Sub_2/y', 'Sub_2', 'Slice_2/begin', 'Slice_2/size', 'Slice_2', 'Reshape_2', 'Const_2', 'Mean_1', 'gradients/Shape', 'gradients/Const', 'gradients/Fill', 'gradients/f_count', 'gradients/f_count_1', 'gradients/Merge', 'gradients/Switch', 'gradients/Add/y', 'gradients/Add', 'gradients/NextIteration', 'gradients/f_count_2', 'gradients/b_count', 'gradients/b_count_1', 'gradients/Merge_1', 'gradients/GreaterEqual/Enter', 'gradients/GreaterEqual', 'gradients/b_count_2', 'gradients/Switch_1', 'gradients/Sub', 'gradients/NextIteration_1', 'gradients/b_count_3', 'gradients/Mean_1_grad/Reshape/shape', 'gradients/Mean_1_grad/Reshape', 'gradients/Mean_1_grad/Tile/multiples', 'gradients/Mean_1_grad/Tile', 'gradients/Mean_1_grad/Shape', 'gradients/Mean_1_grad/Shape_1', 'gradients/Mean_1_grad/Const', 'gradients/Mean_1_grad/Prod', 'gradients/Mean_1_grad/Const_1', 'gradients/Mean_1_grad/Prod_1', 'gradients/Mean_1_grad/Maximum/y', 'gradients/Mean_1_grad/Maximum', 'gradients/Mean_1_grad/floordiv', 'gradients/Mean_1_grad/Cast', 'gradients/Mean_1_grad/truediv', 'gradients/Reshape_2_grad/Shape', 'gradients/Reshape_2_grad/Reshape', 'gradients/zeros_like', 'gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim', 'gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims', 'gradients/SoftmaxCrossEntropyWithLogits_grad/mul', 'gradients/Reshape_grad/Shape', 'gradients/Reshape_grad/Reshape', 'gradients/add_grad/Shape', 'gradients/add_grad/Shape_1', 'gradients/add_grad/BroadcastGradientArgs', 'gradients/add_grad/Sum', 'gradients/add_grad/Reshape', 'gradients/add_grad/Sum_1', 'gradients/add_grad/Reshape_1', 'gradients/add_grad/tuple/group_deps', 'gradients/add_grad/tuple/control_dependency', 'gradients/add_grad/tuple/control_dependency_1', 'gradients/MatMul_grad/MatMul', 'gradients/MatMul_grad/MatMul_1', 'gradients/MatMul_grad/tuple/group_deps', 'gradients/MatMul_grad/tuple/control_dependency', 'gradients/MatMul_grad/tuple/control_dependency_1', 'gradients/Gather_grad/Shape', 'gradients/Gather_grad/ToInt32', 'gradients/Gather_grad/Size', 'gradients/Gather_grad/ExpandDims/dim', 'gradients/Gather_grad/ExpandDims', 'gradients/Gather_grad/strided_slice/stack', 'gradients/Gather_grad/strided_slice/stack_1', 'gradients/Gather_grad/strided_slice/stack_2', 'gradients/Gather_grad/strided_slice', 'gradients/Gather_grad/concat/axis', 'gradients/Gather_grad/concat', 'gradients/Gather_grad/Reshape', 'gradients/Gather_grad/Reshape_1', 'gradients/transpose_1_grad/InvertPermutation', 'gradients/transpose_1_grad/transpose/strided_slice/stack', 'gradients/transpose_1_grad/transpose/strided_slice/stack_1', 'gradients/transpose_1_grad/transpose/strided_slice/stack_2', 'gradients/transpose_1_grad/transpose/strided_slice', 'gradients/transpose_1_grad/transpose/x', 'gradients/transpose_1_grad/transpose', 'gradients/rnn/transpose_grad/InvertPermutation', 'gradients/rnn/transpose_grad/transpose', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3', 'gradients/zeros', 'gradients/zeros_1', 'gradients/rnn/while/Exit_1_grad/b_exit', 'gradients/rnn/while/Exit_2_grad/b_exit', 'gradients/rnn/while/Exit_3_grad/b_exit', 'gradients/rnn/while/Switch_1_grad/b_switch', 'gradients/rnn/while/Switch_2_grad/b_switch', 'gradients/rnn/while/Switch_3_grad/b_switch', 'gradients/rnn/while/Merge_1_grad/Switch', 'gradients/rnn/while/Merge_1_grad/tuple/group_deps', 'gradients/rnn/while/Merge_1_grad/tuple/control_dependency', 'gradients/rnn/while/Merge_1_grad/tuple/control_dependency_1', 'gradients/rnn/while/Merge_2_grad/Switch', 'gradients/rnn/while/Merge_2_grad/tuple/group_deps', 'gradients/rnn/while/Merge_2_grad/tuple/control_dependency', 'gradients/rnn/while/Merge_2_grad/tuple/control_dependency_1', 'gradients/rnn/while/Merge_3_grad/Switch', 'gradients/rnn/while/Merge_3_grad/tuple/group_deps', 'gradients/rnn/while/Merge_3_grad/tuple/control_dependency', 'gradients/rnn/while/Merge_3_grad/tuple/control_dependency_1', 'gradients/rnn/while/Enter_1_grad/Exit', 'gradients/rnn/while/Enter_2_grad/Exit', 'gradients/rnn/while/Enter_3_grad/Exit', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc/max_size', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPushV2', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1', 'gradients/rnn/while/dropout/mul_grad/Shape', 'gradients/rnn/while/dropout/mul_grad/Shape_1', 'gradients/rnn/while/dropout/mul_grad/BroadcastGradientArgs', 'gradients/rnn/while/dropout/mul_grad/mul/f_acc/max_size', 'gradients/rnn/while/dropout/mul_grad/mul/f_acc', 'gradients/rnn/while/dropout/mul_grad/mul/Enter', 'gradients/rnn/while/dropout/mul_grad/mul/StackPushV2', 'gradients/rnn/while/dropout/mul_grad/mul/StackPopV2/Enter', 'gradients/rnn/while/dropout/mul_grad/mul/StackPopV2', 'gradients/rnn/while/dropout/mul_grad/mul', 'gradients/rnn/while/dropout/mul_grad/Sum', 'gradients/rnn/while/dropout/mul_grad/Reshape', 'gradients/rnn/while/dropout/mul_grad/mul_1/f_acc/max_size', 'gradients/rnn/while/dropout/mul_grad/mul_1/f_acc', 'gradients/rnn/while/dropout/mul_grad/mul_1/Enter', 'gradients/rnn/while/dropout/mul_grad/mul_1/StackPushV2', 'gradients/rnn/while/dropout/mul_grad/mul_1/StackPopV2/Enter', 'gradients/rnn/while/dropout/mul_grad/mul_1/StackPopV2', 'gradients/rnn/while/dropout/mul_grad/mul_1', 'gradients/rnn/while/dropout/mul_grad/Sum_1', 'gradients/rnn/while/dropout/mul_grad/Reshape_1', 'gradients/rnn/while/dropout/mul_grad/tuple/group_deps', 'gradients/rnn/while/dropout/mul_grad/tuple/control_dependency', 'gradients/rnn/while/dropout/mul_grad/tuple/control_dependency_1', 'gradients/rnn/while/dropout/div_grad/Shape', 'gradients/rnn/while/dropout/div_grad/Shape_1', 'gradients/rnn/while/dropout/div_grad/BroadcastGradientArgs', 'gradients/rnn/while/dropout/div_grad/RealDiv/Const', 'gradients/rnn/while/dropout/div_grad/RealDiv', 'gradients/rnn/while/dropout/div_grad/Sum', 'gradients/rnn/while/dropout/div_grad/Reshape', 'gradients/rnn/while/dropout/div_grad/Neg/f_acc/max_size', 'gradients/rnn/while/dropout/div_grad/Neg/f_acc', 'gradients/rnn/while/dropout/div_grad/Neg/Enter', 'gradients/rnn/while/dropout/div_grad/Neg/StackPushV2', 'gradients/rnn/while/dropout/div_grad/Neg/StackPopV2/Enter', 'gradients/rnn/while/dropout/div_grad/Neg/StackPopV2', 'gradients/rnn/while/dropout/div_grad/Neg', 'gradients/rnn/while/dropout/div_grad/RealDiv_1', 'gradients/rnn/while/dropout/div_grad/RealDiv_2', 'gradients/rnn/while/dropout/div_grad/mul', 'gradients/rnn/while/dropout/div_grad/Sum_1', 'gradients/rnn/while/dropout/div_grad/Reshape_1', 'gradients/rnn/while/dropout/div_grad/tuple/group_deps', 'gradients/rnn/while/dropout/div_grad/tuple/control_dependency', 'gradients/rnn/while/dropout/div_grad/tuple/control_dependency_1', 'gradients/rnn/while/Switch_1_grad_1/NextIteration', 'gradients/AddN', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/BroadcastGradientArgs', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Sum', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Reshape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/mul_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Sum_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/Reshape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_2_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/Tanh_1_grad/TanhGrad', 'gradients/rnn/while/rnn/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad', 'gradients/AddN_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/BroadcastGradientArgs', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Sum', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Reshape', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Sum_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/Reshape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/add_1_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/BroadcastGradientArgs', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Sum', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Reshape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/mul_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Sum_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/Reshape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/BroadcastGradientArgs', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Sum', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Reshape', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/mul_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Sum_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/Reshape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/mul_1_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/Sigmoid_grad/SigmoidGrad', 'gradients/rnn/while/rnn/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad', 'gradients/rnn/while/rnn/basic_lstm_cell/Tanh_grad/TanhGrad', 'gradients/rnn/while/Switch_2_grad_1/NextIteration', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/BroadcastGradientArgs', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Sum', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Reshape', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Sum_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/Reshape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/add_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/split_grad/concat/Const', 'gradients/rnn/while/rnn/basic_lstm_cell/split_grad/concat', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd_grad/BiasAddGrad', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/f_acc/max_size', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/f_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/StackPushV2', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/StackPopV2/Enter', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1/StackPopV2', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/MatMul_1', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/b_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_1', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_2', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/Switch', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/Add', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/NextIteration', 'gradients/rnn/while/rnn/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/Rank', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/mod/Const', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/mod', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/Shape', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/Shape_1', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/ConcatOffset', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/Slice', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/Slice_1', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/tuple/group_deps', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/tuple/control_dependency', 'gradients/rnn/while/rnn/basic_lstm_cell/concat_grad/tuple/control_dependency_1', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/b_acc', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/b_acc_1', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/b_acc_2', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/Switch', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/Add', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/NextIteration', 'gradients/rnn/while/rnn/basic_lstm_cell/MatMul/Enter_grad/b_acc_3', 'gradients/rnn/while/Switch_3_grad_1/NextIteration', 'beta1_power/initial_value', 'beta1_power', 'beta1_power/Assign', 'beta1_power/read', 'beta2_power/initial_value', 'beta2_power', 'beta2_power/Assign', 'beta2_power/read', 'rnn/basic_lstm_cell/kernel/Adam/Initializer/zeros', 'rnn/basic_lstm_cell/kernel/Adam', 'rnn/basic_lstm_cell/kernel/Adam/Assign', 'rnn/basic_lstm_cell/kernel/Adam/read', 'rnn/basic_lstm_cell/kernel/Adam_1/Initializer/zeros', 'rnn/basic_lstm_cell/kernel/Adam_1', 'rnn/basic_lstm_cell/kernel/Adam_1/Assign', 'rnn/basic_lstm_cell/kernel/Adam_1/read', 'rnn/basic_lstm_cell/bias/Adam/Initializer/zeros', 'rnn/basic_lstm_cell/bias/Adam', 'rnn/basic_lstm_cell/bias/Adam/Assign', 'rnn/basic_lstm_cell/bias/Adam/read', 'rnn/basic_lstm_cell/bias/Adam_1/Initializer/zeros', 'rnn/basic_lstm_cell/bias/Adam_1', 'rnn/basic_lstm_cell/bias/Adam_1/Assign', 'rnn/basic_lstm_cell/bias/Adam_1/read', 'Variable_1/Adam/Initializer/zeros', 'Variable_1/Adam', 'Variable_1/Adam/Assign', 'Variable_1/Adam/read', 'Variable_1/Adam_1/Initializer/zeros', 'Variable_1/Adam_1', 'Variable_1/Adam_1/Assign', 'Variable_1/Adam_1/read', 'Variable_2/Adam/Initializer/zeros', 'Variable_2/Adam', 'Variable_2/Adam/Assign', 'Variable_2/Adam/read', 'Variable_2/Adam_1/Initializer/zeros', 'Variable_2/Adam_1', 'Variable_2/Adam_1/Assign', 'Variable_2/Adam_1/read', 'Adam/learning_rate', 'Adam/beta1', 'Adam/beta2', 'Adam/epsilon', 'Adam/update_rnn/basic_lstm_cell/kernel/ApplyAdam', 'Adam/update_rnn/basic_lstm_cell/bias/ApplyAdam', 'Adam/update_Variable_1/ApplyAdam', 'Adam/update_Variable_2/ApplyAdam', 'Adam/mul', 'Adam/Assign', 'Adam/mul_1', 'Adam/Assign_1', 'Adam', 'Loss/tags', 'Loss', 'Accuracy/tags', 'Accuracy', 'Merge/MergeSummary', 'Loss_1/tags', 'Loss_1', 'Accuracy_1/tags', 'Accuracy_1', 'Merge_1/MergeSummary', 'Loss_2/tags', 'Loss_2', 'Accuracy_2/tags', 'Accuracy_2', 'Merge_2/MergeSummary', 'save/Const', 'save/SaveV2/tensor_names', 'save/SaveV2/shape_and_slices', 'save/SaveV2', 'save/control_dependency', 'save/RestoreV2/tensor_names', 'save/RestoreV2/shape_and_slices', 'save/RestoreV2', 'save/Assign', 'save/RestoreV2_1/tensor_names', 'save/RestoreV2_1/shape_and_slices', 'save/RestoreV2_1', 'save/Assign_1', 'save/RestoreV2_2/tensor_names', 'save/RestoreV2_2/shape_and_slices', 'save/RestoreV2_2', 'save/Assign_2', 'save/RestoreV2_3/tensor_names', 'save/RestoreV2_3/shape_and_slices', 'save/RestoreV2_3', 'save/Assign_3', 'save/RestoreV2_4/tensor_names', 'save/RestoreV2_4/shape_and_slices', 'save/RestoreV2_4', 'save/Assign_4', 'save/RestoreV2_5/tensor_names', 'save/RestoreV2_5/shape_and_slices', 'save/RestoreV2_5', 'save/Assign_5', 'save/RestoreV2_6/tensor_names', 'save/RestoreV2_6/shape_and_slices', 'save/RestoreV2_6', 'save/Assign_6', 'save/RestoreV2_7/tensor_names', 'save/RestoreV2_7/shape_and_slices', 'save/RestoreV2_7', 'save/Assign_7', 'save/RestoreV2_8/tensor_names', 'save/RestoreV2_8/shape_and_slices', 'save/RestoreV2_8', 'save/Assign_8', 'save/RestoreV2_9/tensor_names', 'save/RestoreV2_9/shape_and_slices', 'save/RestoreV2_9', 'save/Assign_9', 'save/RestoreV2_10/tensor_names', 'save/RestoreV2_10/shape_and_slices', 'save/RestoreV2_10', 'save/Assign_10', 'save/RestoreV2_11/tensor_names', 'save/RestoreV2_11/shape_and_slices', 'save/RestoreV2_11', 'save/Assign_11', 'save/RestoreV2_12/tensor_names', 'save/RestoreV2_12/shape_and_slices', 'save/RestoreV2_12', 'save/Assign_12', 'save/RestoreV2_13/tensor_names', 'save/RestoreV2_13/shape_and_slices', 'save/RestoreV2_13', 'save/Assign_13', 'save/RestoreV2_14/tensor_names', 'save/RestoreV2_14/shape_and_slices', 'save/RestoreV2_14', 'save/Assign_14', 'save/restore_all', 'Placeholder_2', 'Placeholder_1_1', 'zeros_1', 'Variable_3', 'Variable/Assign_1', 'Variable/read_1', 'embedding_lookup/params_0_1', 'embedding_lookup_1', 'DropoutWrapperInit/Const_3', 'DropoutWrapperInit/Const_1_1', 'DropoutWrapperInit/Const_2_1', 'rnn/Rank_1', 'rnn/range/start_1', 'rnn/range/delta_1', 'rnn/range_1', 'rnn/concat/values_0', 'rnn/concat/axis_1', 'rnn/concat_2', 'rnn/transpose_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_8', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_1_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_2', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_2', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_3_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_4_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_5_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_6_1', 'rnn/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_7_1', 'rnn/Shape_1', 'rnn/strided_slice/stack_3', 'rnn/strided_slice/stack_1_1', 'rnn/strided_slice/stack_2_1', 'rnn/strided_slice_1', 'rnn/Const_4', 'rnn/Const_1_1', 'rnn/concat_1/axis_1', 'rnn/concat_1_1', 'rnn/zeros/Const_1', 'rnn/zeros_1', 'rnn/time_1', 'rnn/TensorArray_2', 'rnn/TensorArray_1_1', 'rnn/TensorArrayUnstack/Shape_1', 'rnn/TensorArrayUnstack/strided_slice/stack_3', 'rnn/TensorArrayUnstack/strided_slice/stack_1_1', 'rnn/TensorArrayUnstack/strided_slice/stack_2_1', 'rnn/TensorArrayUnstack/strided_slice_1', 'rnn/TensorArrayUnstack/range/start_1', 'rnn/TensorArrayUnstack/range/delta_1', 'rnn/TensorArrayUnstack/range_1', 'rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_1', 'rnn/while/iteration_counter', 'rnn/while/Enter_4', 'rnn/while/Enter_1_1', 'rnn/while/Enter_2_1', 'rnn/while/Enter_3_1', 'rnn/while/Enter_4_1', 'rnn/while/Merge_4', 'rnn/while/Merge_1_1', 'rnn/while/Merge_2_1', 'rnn/while/Merge_3_1', 'rnn/while/Merge_4_1', 'rnn/while/Less_1', 'rnn/while/Less/Enter_1', 'rnn/while/Less_1_1', 'rnn/while/LogicalAnd', 'rnn/while/LoopCond_1', 'rnn/while/Switch_4', 'rnn/while/Switch_1_1', 'rnn/while/Switch_2_1', 'rnn/while/Switch_3_1', 'rnn/while/Switch_4_1', 'rnn/while/Identity_4', 'rnn/while/Identity_1_1', 'rnn/while/Identity_2_1', 'rnn/while/Identity_3_1', 'rnn/while/Identity_4_1', 'rnn/while/add/y_1', 'rnn/while/add_1', 'rnn/while/TensorArrayReadV3_1', 'rnn/while/TensorArrayReadV3/Enter_2', 'rnn/while/TensorArrayReadV3/Enter_1_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/shape_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/min_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/max_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/sub_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform/mul_1', 'rnn/basic_lstm_cell/kernel/Initializer/random_uniform_1', 'rnn/basic_lstm_cell/kernel_1', 'rnn/basic_lstm_cell/kernel/Assign_1', 'rnn/basic_lstm_cell/kernel/read_1', 'rnn/basic_lstm_cell/bias/Initializer/zeros', 'rnn/basic_lstm_cell/bias_1', 'rnn/basic_lstm_cell/bias/Assign_1', 'rnn/basic_lstm_cell/bias/read_1', 'rnn/while/basic_lstm_cell/Const', 'rnn/while/basic_lstm_cell/concat/axis', 'rnn/while/basic_lstm_cell/concat', 'rnn/while/basic_lstm_cell/MatMul', 'rnn/while/basic_lstm_cell/MatMul/Enter', 'rnn/while/basic_lstm_cell/BiasAdd', 'rnn/while/basic_lstm_cell/BiasAdd/Enter', 'rnn/while/basic_lstm_cell/Const_1', 'rnn/while/basic_lstm_cell/split', 'rnn/while/basic_lstm_cell/Const_2', 'rnn/while/basic_lstm_cell/Add', 'rnn/while/basic_lstm_cell/Sigmoid', 'rnn/while/basic_lstm_cell/Mul', 'rnn/while/basic_lstm_cell/Sigmoid_1', 'rnn/while/basic_lstm_cell/Tanh', 'rnn/while/basic_lstm_cell/Mul_1', 'rnn/while/basic_lstm_cell/Add_1', 'rnn/while/basic_lstm_cell/Tanh_1', 'rnn/while/basic_lstm_cell/Sigmoid_2', 'rnn/while/basic_lstm_cell/Mul_2', 'rnn/while/dropout/keep_prob_1', 'rnn/while/dropout/Shape_1', 'rnn/while/dropout/random_uniform/min_1', 'rnn/while/dropout/random_uniform/max_1', 'rnn/while/dropout/random_uniform/RandomUniform_1', 'rnn/while/dropout/random_uniform/sub_1', 'rnn/while/dropout/random_uniform/mul_1', 'rnn/while/dropout/random_uniform_1', 'rnn/while/dropout/add_1', 'rnn/while/dropout/Floor_1', 'rnn/while/dropout/div_1', 'rnn/while/dropout/mul_1', 'rnn/while/TensorArrayWrite/TensorArrayWriteV3_1', 'rnn/while/TensorArrayWrite/TensorArrayWriteV3/Enter_1', 'rnn/while/add_1/y', 'rnn/while/add_1_1', 'rnn/while/NextIteration_4', 'rnn/while/NextIteration_1_1', 'rnn/while/NextIteration_2_1', 'rnn/while/NextIteration_3_1', 'rnn/while/NextIteration_4_1', 'rnn/while/Exit_4', 'rnn/while/Exit_1_1', 'rnn/while/Exit_2_1', 'rnn/while/Exit_3_1', 'rnn/while/Exit_4_1', 'rnn/TensorArrayStack/TensorArraySizeV3_1', 'rnn/TensorArrayStack/range/start_1', 'rnn/TensorArrayStack/range/delta_1', 'rnn/TensorArrayStack/range_1', 'rnn/TensorArrayStack/TensorArrayGatherV3_1', 'rnn/Const_2_1', 'rnn/Const_3_1', 'rnn/Rank_1_1', 'rnn/range_1/start', 'rnn/range_1/delta', 'rnn/range_1_1', 'rnn/concat_2/values_0', 'rnn/concat_2/axis', 'rnn/concat_2_1', 'rnn/transpose_1_1', 'truncated_normal/shape_1', 'truncated_normal/mean_1', 'truncated_normal/stddev_1', 'truncated_normal/TruncatedNormal_1', 'truncated_normal/mul_1', 'truncated_normal_1', 'Variable_1_1', 'Variable_1/Assign_1', 'Variable_1/read_1', 'Const_3', 'Variable_2_1', 'Variable_2/Assign_1', 'Variable_2/read_1', 'transpose/perm', 'transpose_2', 'Gather/indices_1', 'Gather_1', 'MatMul_1', 'add_1', 'ArgMax/dimension_1', 'ArgMax_2', 'ArgMax_1/dimension_1', 'ArgMax_1_1', 'Equal_1', 'Cast_2', 'Const_1_1', 'Mean_2', 'softmax_cross_entropy_with_logits_sg/labels_stop_gradient', 'softmax_cross_entropy_with_logits_sg/Rank', 'softmax_cross_entropy_with_logits_sg/Shape', 'softmax_cross_entropy_with_logits_sg/Rank_1', 'softmax_cross_entropy_with_logits_sg/Shape_1', 'softmax_cross_entropy_with_logits_sg/Sub/y', 'softmax_cross_entropy_with_logits_sg/Sub', 'softmax_cross_entropy_with_logits_sg/Slice/begin', 'softmax_cross_entropy_with_logits_sg/Slice/size', 'softmax_cross_entropy_with_logits_sg/Slice', 'softmax_cross_entropy_with_logits_sg/concat/values_0', 'softmax_cross_entropy_with_logits_sg/concat/axis', 'softmax_cross_entropy_with_logits_sg/concat', 'softmax_cross_entropy_with_logits_sg/Reshape', 'softmax_cross_entropy_with_logits_sg/Rank_2', 'softmax_cross_entropy_with_logits_sg/Shape_2', 'softmax_cross_entropy_with_logits_sg/Sub_1/y', 'softmax_cross_entropy_with_logits_sg/Sub_1', 'softmax_cross_entropy_with_logits_sg/Slice_1/begin', 'softmax_cross_entropy_with_logits_sg/Slice_1/size', 'softmax_cross_entropy_with_logits_sg/Slice_1', 'softmax_cross_entropy_with_logits_sg/concat_1/values_0', 'softmax_cross_entropy_with_logits_sg/concat_1/axis', 'softmax_cross_entropy_with_logits_sg/concat_1', 'softmax_cross_entropy_with_logits_sg/Reshape_1', 'softmax_cross_entropy_with_logits_sg', 'softmax_cross_entropy_with_logits_sg/Sub_2/y', 'softmax_cross_entropy_with_logits_sg/Sub_2', 'softmax_cross_entropy_with_logits_sg/Slice_2/begin', 'softmax_cross_entropy_with_logits_sg/Slice_2/size', 'softmax_cross_entropy_with_logits_sg/Slice_2', 'softmax_cross_entropy_with_logits_sg/Reshape_2', 'Const_2_1', 'Mean_1_1', 'gradients/Shape_1', 'gradients/grad_ys_0', 'gradients/Fill_1', 'gradients/f_count_3', 'gradients/f_count_1_1', 'gradients/Merge_2', 'gradients/Switch_2', 'gradients/Add/y_1', 'gradients/Add_1', 'gradients/NextIteration_2', 'gradients/f_count_2_1', 'gradients/b_count_4', 'gradients/b_count_1_1', 'gradients/Merge_1_1', 'gradients/GreaterEqual_1', 'gradients/GreaterEqual/Enter_1', 'gradients/b_count_2_1', 'gradients/Switch_1_1', 'gradients/Sub_1', 'gradients/NextIteration_1_1', 'gradients/b_count_3_1', 'gradients/Mean_1_grad/Reshape/shape_1', 'gradients/Mean_1_grad/Reshape_1', 'gradients/Mean_1_grad/Tile/multiples_1', 'gradients/Mean_1_grad/Tile_1', 'gradients/Mean_1_grad/Const_2', 'gradients/Mean_1_grad/truediv_1', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Shape', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape', 'gradients/zeros_like_1', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims/dim', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims', 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul', 'gradients/softmax_cross_entropy_with_logits_sg_grad/LogSoftmax', 'gradients/softmax_cross_entropy_with_logits_sg_grad/Neg', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1/dim', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1', 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul_1', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency_1', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Shape', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape', 'gradients/add_grad/Shape_2', 'gradients/add_grad/Shape_1_1', 'gradients/add_grad/BroadcastGradientArgs_1', 'gradients/add_grad/Sum_2', 'gradients/add_grad/Reshape_2', 'gradients/add_grad/Sum_1_1', 'gradients/add_grad/Reshape_1_1', 'gradients/add_grad/tuple/group_deps_1', 'gradients/add_grad/tuple/control_dependency_2', 'gradients/add_grad/tuple/control_dependency_1_1', 'gradients/MatMul_grad/MatMul_2', 'gradients/MatMul_grad/MatMul_1_1', 'gradients/MatMul_grad/tuple/group_deps_1', 'gradients/MatMul_grad/tuple/control_dependency_2', 'gradients/MatMul_grad/tuple/control_dependency_1_1', 'gradients/Gather_grad/Shape_1', 'gradients/Gather_grad/ToInt32_1', 'gradients/Gather_grad/Size_1', 'gradients/Gather_grad/ExpandDims/dim_1', 'gradients/Gather_grad/ExpandDims_1', 'gradients/Gather_grad/strided_slice/stack_3', 'gradients/Gather_grad/strided_slice/stack_1_1', 'gradients/Gather_grad/strided_slice/stack_2_1', 'gradients/Gather_grad/strided_slice_1', 'gradients/Gather_grad/concat/axis_1', 'gradients/Gather_grad/concat_1', 'gradients/Gather_grad/Reshape_2', 'gradients/Gather_grad/Reshape_1_1', 'gradients/transpose_grad/InvertPermutation', 'gradients/transpose_grad/transpose/strided_slice/stack', 'gradients/transpose_grad/transpose/strided_slice/stack_1', 'gradients/transpose_grad/transpose/strided_slice/stack_2', 'gradients/transpose_grad/transpose/strided_slice', 'gradients/transpose_grad/transpose/x', 'gradients/transpose_grad/transpose', 'gradients/rnn/transpose_1_grad/InvertPermutation', 'gradients/rnn/transpose_1_grad/transpose', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3_1', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow_1', 'gradients/rnn/TensorArrayStack/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3_1', 'gradients/zeros_2', 'gradients/zeros_1_1', 'gradients/rnn/while/Exit_2_grad/b_exit_1', 'gradients/rnn/while/Exit_3_grad/b_exit_1', 'gradients/rnn/while/Exit_4_grad/b_exit', 'gradients/rnn/while/Switch_2_grad/b_switch_1', 'gradients/rnn/while/Switch_3_grad/b_switch_1', 'gradients/rnn/while/Switch_4_grad/b_switch', 'gradients/rnn/while/Merge_2_grad/Switch_1', 'gradients/rnn/while/Merge_2_grad/tuple/group_deps_1', 'gradients/rnn/while/Merge_2_grad/tuple/control_dependency_2', 'gradients/rnn/while/Merge_2_grad/tuple/control_dependency_1_1', 'gradients/rnn/while/Merge_3_grad/Switch_1', 'gradients/rnn/while/Merge_3_grad/tuple/group_deps_1', 'gradients/rnn/while/Merge_3_grad/tuple/control_dependency_2', 'gradients/rnn/while/Merge_3_grad/tuple/control_dependency_1_1', 'gradients/rnn/while/Merge_4_grad/Switch', 'gradients/rnn/while/Merge_4_grad/tuple/group_deps', 'gradients/rnn/while/Merge_4_grad/tuple/control_dependency', 'gradients/rnn/while/Merge_4_grad/tuple/control_dependency_1', 'gradients/rnn/while/Enter_2_grad/Exit_1', 'gradients/rnn/while/Enter_3_grad/Exit_1', 'gradients/rnn/while/Enter_4_grad/Exit', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3/Enter_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/gradient_flow_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/Enter_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPushV2_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2/Enter_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/b_sync_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/group_deps_1', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_2', 'gradients/rnn/while/TensorArrayWrite/TensorArrayWriteV3_grad/tuple/control_dependency_1_1', 'gradients/rnn/while/dropout/mul_grad/Mul', 'gradients/rnn/while/dropout/mul_grad/Mul/f_acc', 'gradients/rnn/while/dropout/mul_grad/Mul/Enter', 'gradients/rnn/while/dropout/mul_grad/Mul/StackPushV2', 'gradients/rnn/while/dropout/mul_grad/Mul/StackPopV2', 'gradients/rnn/while/dropout/mul_grad/Mul/StackPopV2/Enter', 'gradients/rnn/while/dropout/mul_grad/Mul_1', 'gradients/rnn/while/dropout/mul_grad/Mul_1/f_acc', 'gradients/rnn/while/dropout/mul_grad/Mul_1/Enter', 'gradients/rnn/while/dropout/mul_grad/Mul_1/StackPushV2', 'gradients/rnn/while/dropout/mul_grad/Mul_1/StackPopV2', 'gradients/rnn/while/dropout/mul_grad/Mul_1/StackPopV2/Enter', 'gradients/rnn/while/dropout/mul_grad/tuple/group_deps_1', 'gradients/rnn/while/dropout/mul_grad/tuple/control_dependency_2', 'gradients/rnn/while/dropout/mul_grad/tuple/control_dependency_1_1', 'gradients/rnn/while/dropout/div_grad/Shape_2', 'gradients/rnn/while/dropout/div_grad/Shape_1_1', 'gradients/rnn/while/dropout/div_grad/BroadcastGradientArgs_1', 'gradients/rnn/while/dropout/div_grad/RealDiv_3', 'gradients/rnn/while/dropout/div_grad/RealDiv/Const_1', 'gradients/rnn/while/dropout/div_grad/Sum_2', 'gradients/rnn/while/dropout/div_grad/Reshape_2', 'gradients/rnn/while/dropout/div_grad/Neg_1', 'gradients/rnn/while/dropout/div_grad/Neg/f_acc_1', 'gradients/rnn/while/dropout/div_grad/Neg/Enter_1', 'gradients/rnn/while/dropout/div_grad/Neg/StackPushV2_1', 'gradients/rnn/while/dropout/div_grad/Neg/StackPopV2_1', 'gradients/rnn/while/dropout/div_grad/Neg/StackPopV2/Enter_1', 'gradients/rnn/while/dropout/div_grad/RealDiv_1_1', 'gradients/rnn/while/dropout/div_grad/RealDiv_2_1', 'gradients/rnn/while/dropout/div_grad/mul_1', 'gradients/rnn/while/dropout/div_grad/Sum_1_1', 'gradients/rnn/while/dropout/div_grad/Reshape_1_1', 'gradients/rnn/while/dropout/div_grad/tuple/group_deps_1', 'gradients/rnn/while/dropout/div_grad/tuple/control_dependency_2', 'gradients/rnn/while/dropout/div_grad/tuple/control_dependency_1_1', 'gradients/rnn/while/Switch_2_grad_1/NextIteration_1', 'gradients/AddN_2', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/Mul_1/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/Mul_2_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/Tanh_1_grad/TanhGrad', 'gradients/rnn/while/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad', 'gradients/AddN_1_1', 'gradients/rnn/while/basic_lstm_cell/Add_1_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/Add_1_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/Mul_1/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/Mul_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1/f_acc', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/Mul_1/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/Mul_1_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/Sigmoid_grad/SigmoidGrad', 'gradients/rnn/while/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad', 'gradients/rnn/while/basic_lstm_cell/Tanh_grad/TanhGrad', 'gradients/rnn/while/Switch_3_grad_1/NextIteration_1', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Shape', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Shape_1', 'gradients/rnn/while/basic_lstm_cell/Add_grad/BroadcastGradientArgs', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Sum', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Reshape', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Sum_1', 'gradients/rnn/while/basic_lstm_cell/Add_grad/Reshape_1', 'gradients/rnn/while/basic_lstm_cell/Add_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/Add_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/Add_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/split_grad/concat', 'gradients/rnn/while/basic_lstm_cell/split_grad/concat/Const', 'gradients/rnn/while/basic_lstm_cell/BiasAdd_grad/BiasAddGrad', 'gradients/rnn/while/basic_lstm_cell/BiasAdd_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul/Enter', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1/f_acc', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1/Enter', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1/StackPushV2', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1/StackPopV2', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/MatMul_1/StackPopV2/Enter', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/b_acc', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_1', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_2', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/Switch', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/Add', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/NextIteration', 'gradients/rnn/while/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3', 'gradients/rnn/while/basic_lstm_cell/concat_grad/Rank', 'gradients/rnn/while/basic_lstm_cell/concat_grad/mod', 'gradients/rnn/while/basic_lstm_cell/concat_grad/mod/Const', 'gradients/rnn/while/basic_lstm_cell/concat_grad/Shape', 'gradients/rnn/while/basic_lstm_cell/concat_grad/Shape_1', 'gradients/rnn/while/basic_lstm_cell/concat_grad/ConcatOffset', 'gradients/rnn/while/basic_lstm_cell/concat_grad/Slice', 'gradients/rnn/while/basic_lstm_cell/concat_grad/Slice_1', 'gradients/rnn/while/basic_lstm_cell/concat_grad/tuple/group_deps', 'gradients/rnn/while/basic_lstm_cell/concat_grad/tuple/control_dependency', 'gradients/rnn/while/basic_lstm_cell/concat_grad/tuple/control_dependency_1', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/b_acc', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/b_acc_1', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/b_acc_2', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/Switch', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/Add', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/NextIteration', 'gradients/rnn/while/basic_lstm_cell/MatMul/Enter_grad/b_acc_3', 'gradients/rnn/while/Switch_4_grad_1/NextIteration', 'beta1_power/initial_value_1', 'beta1_power_1', 'beta1_power/Assign_1', 'beta1_power/read_1', 'beta2_power/initial_value_1', 'beta2_power_1', 'beta2_power/Assign_1', 'beta2_power/read_1', 'rnn/basic_lstm_cell/kernel/Adam/Initializer/zeros_1', 'rnn/basic_lstm_cell/kernel/Adam_2', 'rnn/basic_lstm_cell/kernel/Adam/Assign_1', 'rnn/basic_lstm_cell/kernel/Adam/read_1', 'rnn/basic_lstm_cell/kernel/Adam_1/Initializer/zeros_1', 'rnn/basic_lstm_cell/kernel/Adam_1_1', 'rnn/basic_lstm_cell/kernel/Adam_1/Assign_1', 'rnn/basic_lstm_cell/kernel/Adam_1/read_1', 'rnn/basic_lstm_cell/bias/Adam/Initializer/zeros_1', 'rnn/basic_lstm_cell/bias/Adam_2', 'rnn/basic_lstm_cell/bias/Adam/Assign_1', 'rnn/basic_lstm_cell/bias/Adam/read_1', 'rnn/basic_lstm_cell/bias/Adam_1/Initializer/zeros_1', 'rnn/basic_lstm_cell/bias/Adam_1_1', 'rnn/basic_lstm_cell/bias/Adam_1/Assign_1', 'rnn/basic_lstm_cell/bias/Adam_1/read_1', 'Variable_1/Adam/Initializer/zeros_1', 'Variable_1/Adam_2', 'Variable_1/Adam/Assign_1', 'Variable_1/Adam/read_1', 'Variable_1/Adam_1/Initializer/zeros_1', 'Variable_1/Adam_1_1', 'Variable_1/Adam_1/Assign_1', 'Variable_1/Adam_1/read_1', 'Variable_2/Adam/Initializer/zeros_1', 'Variable_2/Adam_2', 'Variable_2/Adam/Assign_1', 'Variable_2/Adam/read_1', 'Variable_2/Adam_1/Initializer/zeros_1', 'Variable_2/Adam_1_1', 'Variable_2/Adam_1/Assign_1', 'Variable_2/Adam_1/read_1', 'Adam/learning_rate_1', 'Adam/beta1_1', 'Adam/beta2_1', 'Adam/epsilon_1', 'Adam/update_rnn/basic_lstm_cell/kernel/ApplyAdam_1', 'Adam/update_rnn/basic_lstm_cell/bias/ApplyAdam_1', 'Adam/update_Variable_1/ApplyAdam_1', 'Adam/update_Variable_2/ApplyAdam_1', 'Adam/mul_2', 'Adam/Assign_2', 'Adam/mul_1_1', 'Adam/Assign_1_1', 'Adam_1', 'Loss/tags_1', 'Loss_3', 'Accuracy/tags_1', 'Accuracy_3', 'Merge/MergeSummary_1', 'save/Const_1', 'save/SaveV2/tensor_names_1', 'save/SaveV2/shape_and_slices_1', 'save/SaveV2_1', 'save/control_dependency_1', 'save/RestoreV2/tensor_names_1', 'save/RestoreV2/shape_and_slices_1', 'save/RestoreV2_15', 'save/Assign_15', 'save/RestoreV2_1/tensor_names_1', 'save/RestoreV2_1/shape_and_slices_1', 'save/RestoreV2_1_1', 'save/Assign_1_1', 'save/RestoreV2_2/tensor_names_1', 'save/RestoreV2_2/shape_and_slices_1', 'save/RestoreV2_2_1', 'save/Assign_2_1', 'save/RestoreV2_3/tensor_names_1', 'save/RestoreV2_3/shape_and_slices_1', 'save/RestoreV2_3_1', 'save/Assign_3_1', 'save/RestoreV2_4/tensor_names_1', 'save/RestoreV2_4/shape_and_slices_1', 'save/RestoreV2_4_1', 'save/Assign_4_1', 'save/RestoreV2_5/tensor_names_1', 'save/RestoreV2_5/shape_and_slices_1', 'save/RestoreV2_5_1', 'save/Assign_5_1', 'save/RestoreV2_6/tensor_names_1', 'save/RestoreV2_6/shape_and_slices_1', 'save/RestoreV2_6_1', 'save/Assign_6_1', 'save/RestoreV2_7/tensor_names_1', 'save/RestoreV2_7/shape_and_slices_1', 'save/RestoreV2_7_1', 'save/Assign_7_1', 'save/RestoreV2_8/tensor_names_1', 'save/RestoreV2_8/shape_and_slices_1', 'save/RestoreV2_8_1', 'save/Assign_8_1', 'save/RestoreV2_9/tensor_names_1', 'save/RestoreV2_9/shape_and_slices_1', 'save/RestoreV2_9_1', 'save/Assign_9_1', 'save/RestoreV2_10/tensor_names_1', 'save/RestoreV2_10/shape_and_slices_1', 'save/RestoreV2_10_1', 'save/Assign_10_1', 'save/RestoreV2_11/tensor_names_1', 'save/RestoreV2_11/shape_and_slices_1', 'save/RestoreV2_11_1', 'save/Assign_11_1', 'save/RestoreV2_12/tensor_names_1', 'save/RestoreV2_12/shape_and_slices_1', 'save/RestoreV2_12_1', 'save/Assign_12_1', 'save/RestoreV2_13/tensor_names_1', 'save/RestoreV2_13/shape_and_slices_1', 'save/RestoreV2_13_1', 'save/Assign_13_1', 'save/RestoreV2_14/tensor_names_1', 'save/RestoreV2_14/shape_and_slices_1', 'save/RestoreV2_14_1', 'save/Assign_14_1', 'save/restore_all_1', 'init']\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "print([op.name for op in graph.get_operations()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3 - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the getTestBatch() function to generate test batches to test our model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 45.8333343267\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 41.6666656733\n",
      "Accuracy for this batch: 33.3333343267\n",
      "Accuracy for this batch: 37.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 33.3333343267\n",
      "Accuracy for this batch: 50.0\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide our own reviews / sentences and see how our model classifies its sentiment! A few helper functions to clean up the provided text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unkown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can provide our own input text like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputText = \"Worst movie of all times. Bad screenplay, pathetic acting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can provide an input text from another dataset. This one is a negative review from the [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputText = '''Nine minutes of psychedelic, pulsating, often symmetric abstract images, \n",
    "# are enough to drive anyone crazy. I did spot a full-frame eye at the start, \n",
    "# and later some birds silhouetted against other colors. It was just not my cup of tea. \n",
    "# It's about 8 minutes too long.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment\n"
     ]
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "if (predictedSentiment[0] > predictedSentiment[1]):\n",
    "    print(\"Positive Sentiment\")\n",
    "else:\n",
    "    print(\"Negative Sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a positive review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secondInputText = \"Interstellar is the best movie I have ever seen. The sotryline is gripping and intense\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can input one from the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondInputText = '''When I was a kid I watched this many times over, \n",
    "# and I remember whistling the \"Happy Cat\" song quite often. \n",
    "# All the songs are great, and actually memorable, unlike many children's musicals, \n",
    "# where the songs are just stuck in for no real reason. The scenes and costumes are lavish, \n",
    "# and the acting is very well-done, which isn't surprising, considering the cast. \n",
    "# I'd recommend this film to children and parents alike, who love magic and fairytales. \n",
    "# And it actually IS a movie you can watch together, as it won't drive adults up the wall.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secondInputMatrix = getSentenceMatrix(secondInputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment\n"
     ]
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: secondInputMatrix})[0]\n",
    "if (predictedSentiment[0] > predictedSentiment[1]):\n",
    "    print(\"Positive Sentiment\")\n",
    "else:\n",
    "    print(\"Negative Sentiment\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
